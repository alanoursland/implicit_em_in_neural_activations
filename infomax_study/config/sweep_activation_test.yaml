# config/sweep_activation_test.yaml
# Test whether activation function matters with properly configured objective
# Hypothesis: With lambda_tc=100 and lambda_wr=10, activation choice may not matter

sweep:
  # Parameter grid
  activation: [identity, relu, softmax, tanh]
  hidden_dim: [16]
  lambda_tc: [100.0]
  lambda_wr: [10.0]
  seed: [1, 2, 3]

# Fixed parameters (same across all runs)
data:
  dataset: "mnist"
  batch_size: 128
  num_workers: 4

model:
  input_dim: 784

loss:
  variance_eps: 0.000001

training:
  epochs: 100
  lr: 0.001
  optimizer: "adam"

logging:
  save_weights: true
  save_metrics_every: 10
  print_every: 10
  output_dir: "results/sweep_activation_test"
